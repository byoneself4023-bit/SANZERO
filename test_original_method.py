#!/usr/bin/env python3
"""
ì›ë³¸ Test_casePedia.ipynb ë°©ì‹ìœ¼ë¡œ pkl íŒŒì¼ ë¡œë”© í…ŒìŠ¤íŠ¸
"""

import pickle
import pandas as pd
import numpy as np
import sys
import os
from pathlib import Path
import zlib

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì •
project_root = Path(__file__).parent
sys.path.append(str(project_root))

def test_original_loading():
    """ì›ë³¸ ë…¸íŠ¸ë¶ê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ë¡œë”© í…ŒìŠ¤íŠ¸"""

    pkl_path = project_root / "app" / "searcher_model.pkl"
    print(f"ğŸ“ ëª¨ë¸ ê²½ë¡œ: {pkl_path}")
    print(f"ğŸ“Š íŒŒì¼ ì¡´ì¬: {pkl_path.exists()}")
    print(f"ğŸ“ íŒŒì¼ í¬ê¸°: {pkl_path.stat().st_size / 1024 / 1024:.2f} MB")

    try:
        print("\nâ³ ì••ì¶• í•´ì œ ì‹œë„...")

        with open(pkl_path, 'rb') as f:
            compressed_data = f.read()

        print("ğŸ“¦ zlib ì••ì¶• í•´ì œ...")
        decompressed_data = zlib.decompress(compressed_data)

        print(f"âœ… ì••ì¶• í•´ì œ ì™„ë£Œ: {len(decompressed_data) / 1024 / 1024:.2f} MB")

        # ì›ë³¸ ë…¸íŠ¸ë¶ì—ì„œ ì‚¬ìš©í•œ ë°©ì‹ ê·¸ëŒ€ë¡œ ì‹œë„
        print("\nğŸ”„ ì›ë³¸ ë°©ì‹ pickle ë¡œë“œ ì‹œë„...")

        # í™˜ê²½ ì¤€ë¹„ - ë…¸íŠ¸ë¶ í™˜ê²½ê³¼ ë™ì¼í•˜ê²Œ
        import warnings
        warnings.filterwarnings('ignore')

        # ëª¨ë“ˆ ì„í¬íŠ¸
        import pandas as pd
        import numpy as np
        from sklearn.feature_extraction.text import TfidfVectorizer
        from sklearn.metrics.pairwise import cosine_similarity

        # pickle ë¡œë“œ
        model_data = pickle.loads(decompressed_data)

        print("âœ… pickle ë¡œë“œ ì„±ê³µ!")

        # êµ¬ì„± ìš”ì†Œ í™•ì¸
        print(f"\nğŸ“‹ ëª¨ë¸ êµ¬ì„± ìš”ì†Œ:")
        for key, value in model_data.items():
            print(f"  - {key}: {type(value)}")
            if hasattr(value, 'shape'):
                print(f"    í˜•íƒœ: {value.shape}")

        # DataFrame ìƒì„¸ í™•ì¸
        if 'df' in model_data:
            df = model_data['df']
            print(f"\nğŸ“Š DataFrame ì •ë³´:")
            print(f"  í–‰ ìˆ˜: {len(df):,}")
            print(f"  ì—´ ìˆ˜: {len(df.columns)}")
            print(f"  ì»¬ëŸ¼: {list(df.columns)}")

            # ìƒ˜í”Œ ë°ì´í„° í™•ì¸
            print(f"\nğŸ“ ìƒ˜í”Œ ë°ì´í„°:")
            for i in range(min(3, len(df))):
                row = df.iloc[i]
                print(f"  {i+1}. {row.name}:")
                for col in df.columns[:3]:  # ì²˜ìŒ 3ê°œ ì»¬ëŸ¼ë§Œ
                    value = str(row[col])[:50]
                    print(f"     {col}: {value}...")

        # Vectorizer í™•ì¸
        if 'vectorizer' in model_data:
            vectorizer = model_data['vectorizer']
            print(f"\nğŸ”¤ Vectorizer ì •ë³´:")
            print(f"  íƒ€ì…: {type(vectorizer)}")
            if hasattr(vectorizer, 'vocabulary_'):
                print(f"  ì–´íœ˜ í¬ê¸°: {len(vectorizer.vocabulary_):,}")

        # TF-IDF Matrix í™•ì¸
        if 'tfidf_matrix' in model_data:
            matrix = model_data['tfidf_matrix']
            print(f"\nğŸ“ˆ TF-IDF Matrix ì •ë³´:")
            print(f"  íƒ€ì…: {type(matrix)}")
            print(f"  í˜•íƒœ: {matrix.shape}")

        return True

    except Exception as e:
        print(f"âŒ ë¡œë”© ì‹¤íŒ¨: {e}")
        import traceback
        print("ìƒì„¸ ì˜¤ë¥˜:")
        traceback.print_exc()
        return False

def test_simple_search():
    """ê°„ë‹¨í•œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” ê°„ë‹¨í•œ ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")

    pkl_path = project_root / "app" / "searcher_model.pkl"

    try:
        # ë¡œë”©
        with open(pkl_path, 'rb') as f:
            compressed_data = f.read()

        decompressed_data = zlib.decompress(compressed_data)
        model_data = pickle.loads(decompressed_data)

        df = model_data['df']
        vectorizer = model_data['vectorizer']
        tfidf_matrix = model_data['tfidf_matrix']

        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
        query = "ì†ê°€ë½ ì ˆë‹¨"
        print(f"ğŸ“ ê²€ìƒ‰ì–´: '{query}'")

        # TF-IDF ë²¡í„°í™”
        query_vector = vectorizer.transform([query])

        # ìœ ì‚¬ë„ ê³„ì‚°
        similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()

        # ìƒìœ„ ê²°ê³¼
        top_indices = np.argsort(similarities)[::-1][:5]

        print(f"ğŸ¯ ê²€ìƒ‰ ê²°ê³¼:")
        for i, idx in enumerate(top_indices, 1):
            similarity = similarities[idx]
            if similarity > 0:
                case_info = df.iloc[idx]
                print(f"  {i}. ìœ ì‚¬ë„: {similarity:.3f}")

                # ì»¬ëŸ¼ì— ë”°ë¼ ì œëª© ì¶”ì¶œ
                title_cols = ['title', 'ì‚¬ê±´ëª…', 'íŒê²°ì œëª©']
                title = "Unknown"
                for col in title_cols:
                    if col in case_info:
                        title = str(case_info[col])[:50]
                        break

                print(f"     ì œëª©: {title}...")

        return True

    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

if __name__ == "__main__":
    print("ğŸš€ ì›ë³¸ ë°©ì‹ pkl ë¡œë”© í…ŒìŠ¤íŠ¸\n")

    # 1. ì›ë³¸ ë°©ì‹ ë¡œë”© í…ŒìŠ¤íŠ¸
    success = test_original_loading()

    if success:
        # 2. ê°„ë‹¨í•œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        test_simple_search()

    print("\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")