#!/usr/bin/env python3
"""
searcher_model.pkl íŒŒì¼ ê°„ë‹¨ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
íŒŒì¼ êµ¬ì¡°ë§Œ ì•ˆì „í•˜ê²Œ í™•ì¸
"""

import zlib
import sys
from pathlib import Path

def safe_analyze():
    """ì•ˆì „í•œ ë°©ë²•ìœ¼ë¡œ pkl íŒŒì¼ ê¸°ë³¸ ì •ë³´ í™•ì¸"""

    pkl_path = Path(__file__).parent.parent / "app" / "searcher_model.pkl"

    print("ğŸ” searcher_model.pkl ê¸°ë³¸ ì •ë³´ í™•ì¸\n")

    if not pkl_path.exists():
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pkl_path}")
        return

    # 1. íŒŒì¼ ê¸°ë³¸ ì •ë³´
    file_size_mb = pkl_path.stat().st_size / (1024 * 1024)
    print(f"ğŸ“ íŒŒì¼ ê²½ë¡œ: {pkl_path}")
    print(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {file_size_mb:.2f} MB")

    # 2. ì••ì¶• í•´ì œ ì‹œë„
    try:
        print("\nğŸ“¦ zlib ì••ì¶• í•´ì œ í…ŒìŠ¤íŠ¸...")
        with open(pkl_path, 'rb') as f:
            compressed_data = f.read()

        decompressed_data = zlib.decompress(compressed_data)
        decompressed_size_mb = len(decompressed_data) / (1024 * 1024)
        print(f"âœ… ì••ì¶• í•´ì œ ì„±ê³µ!")
        print(f"ğŸ“ˆ ì••ì¶• í•´ì œ í›„ í¬ê¸°: {decompressed_size_mb:.2f} MB")
        print(f"ğŸ“Š ì••ì¶•ìœ¨: {(1 - file_size_mb / decompressed_size_mb) * 100:.1f}%")

        # 3. ë°ì´í„° íƒ€ì… íŒíŠ¸ í™•ì¸
        print(f"\nğŸ” ì••ì¶• í•´ì œëœ ë°ì´í„° ì •ë³´:")
        print(f"  íƒ€ì…: {type(decompressed_data)}")
        print(f"  í¬ê¸°: {len(decompressed_data):,} bytes")

        # ì²« 100ë°”ì´íŠ¸ í™•ì¸ (pickle í—¤ë” ì •ë³´)
        header = decompressed_data[:100]
        print(f"  í—¤ë” (ì²« 50ë°”ì´íŠ¸): {header[:50]}")

        # í…ìŠ¤íŠ¸ ë‚´ìš© ì¤‘ í‚¤ì›Œë“œ ê²€ìƒ‰
        text_content = decompressed_data.decode('latin-1', errors='ignore')
        keywords = ['dataframe', 'DataFrame', 'vectorizer', 'tfidf', 'matrix', 'config']

        print(f"\nğŸ” ë‚´ìš© í‚¤ì›Œë“œ ê²€ìƒ‰:")
        for keyword in keywords:
            count = text_content.lower().count(keyword.lower())
            if count > 0:
                print(f"  '{keyword}': {count}íšŒ ë°œê²¬")

    except Exception as e:
        print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")

    # 4. Test_casePedia.ipynb íŒŒì¼ë„ í™•ì¸
    ipynb_path = pkl_path.parent / "Test_casePedia.ipynb"
    if ipynb_path.exists():
        print(f"\nğŸ““ Test_casePedia.ipynb ë°œê²¬!")
        print(f"  ìœ„ì¹˜: {ipynb_path}")
        print(f"  í¬ê¸°: {ipynb_path.stat().st_size / (1024 * 1024):.2f} MB")
    else:
        print(f"\nâŒ Test_casePedia.ipynb íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    print(f"\nğŸ¯ ê²°ë¡ :")
    print(f"  - pkl íŒŒì¼ì€ zlibë¡œ ì••ì¶•ëœ pickle ë°ì´í„°ì…ë‹ˆë‹¤.")
    print(f"  - ì••ì¶• í•´ì œ í›„ í¬ê¸°ê°€ {decompressed_size_mb:.0f}MBë¡œ, ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
    print(f"  - Test_casePedia.ipynbì˜ WorkInjuryCaseSearcher í´ë˜ìŠ¤ë¥¼ ì°¸ì¡°í•˜ì—¬")
    print(f"    ì´ pkl íŒŒì¼ì„ ì•ˆì „í•˜ê²Œ ë¡œë“œí•˜ëŠ” ë°©ë²•ì„ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤.")

if __name__ == "__main__":
    safe_analyze()